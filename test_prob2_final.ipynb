{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Azmi Mohamed Ridwan\n",
    "\n",
    "Email: azmimr@gmail.com\n",
    "\n",
    "## Problem 2:\n",
    "\n",
    "You are given the data data_Problem2.csv. This data contains transactions between different nodes. In the file each row means a transaction with a VALUE from FROM_NODE to TO_NODE. The transaction has direction. \n",
    "\n",
    "This task is the following: \n",
    "Find all the simple cycles in this data. Here a simple cycle is defined as A→ B → C → D → A. For each cycle, compute the accumulated transaction value associated with this cycle. E.g. transaction value (A→ B) + transaction value (B→ C) +   transaction value (C→ D) + transaction value (D→ A). \n",
    "Return the cycle that has the max accumulated transaction value among all simple cycles, and its accumulated transaction value.\n",
    "\n",
    "**Assumption:** I'm assuming that the solution require not to use any Graph based libraries which will make this problem trivial. Therefore, the problem will be to recreate the graph data structure and the algorithm to do search that structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_Problem2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there null values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FROM_NODE    1\n",
       "TO_NODE      0\n",
       "VALUE        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the null row\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Are there null values ? \n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FROM_NODE</th>\n",
       "      <th>TO_NODE</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>271791.828330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>88</td>\n",
       "      <td>1458.625174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>96</td>\n",
       "      <td>86848.361600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "      <td>406695.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76</td>\n",
       "      <td>98</td>\n",
       "      <td>3227.734868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FROM_NODE  TO_NODE          VALUE\n",
       "0          3       76  271791.828330\n",
       "1         76       88    1458.625174\n",
       "2         76       96   86848.361600\n",
       "3          2       76  406695.000000\n",
       "4         76       98    3227.734868"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cast node to correct int type\n",
    "df['FROM_NODE'] = df['FROM_NODE'].astype('int32')\n",
    "df['TO_NODE'] = df['TO_NODE'].astype('int32')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows in the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   5,   6,   7,   8,  10,  11,  12,  13,  14,  15,\n",
       "        16,  18,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,\n",
       "        33,  34,  36,  37,  38,  40,  41,  42,  43,  44,  45,  46,  47,\n",
       "        48,  49,  51,  52,  53,  54,  55,  56,  58,  59,  60,  61,  62,\n",
       "        63,  64,  65,  70,  76,  83,  90, 100, 131, 136, 137, 157, 160,\n",
       "       168, 170, 171, 172, 173, 177, 178], dtype=int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique source nodes\n",
    "np.sort(df['FROM_NODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 10,  62,  70,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,\n",
       "        82,  83,  84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,\n",
       "        95,  96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107,\n",
       "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
       "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134,\n",
       "       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
       "       148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160,\n",
       "       161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173,\n",
       "       174, 175, 176, 177, 178, 179], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique sink nodes\n",
    "np.sort(df['TO_NODE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 62, 70, 76, 83, 90, 100, 131, 136, 137, 157, 160, 168, 170, 171, 172, 173, 177, 178]\n"
     ]
    }
   ],
   "source": [
    "# Intersection between the 2 arrays - only these nodes have a path to a complete cycle.\n",
    "nodes_to_search = list(np.intersect1d(df['FROM_NODE'].unique(),df['TO_NODE'].unique()))\n",
    "print(nodes_to_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   5   6   7   8  10  11  12  13  14  15  16  18  20  21  22\n",
      "  23  24  25  26  27  28  29  30  33  34  36  37  38  40  41  42  43  44\n",
      "  45  46  47  48  49  51  52  53  54  55  56  58  59  60  61  62  63  64\n",
      "  65  70  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87\n",
      "  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105\n",
      " 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123\n",
      " 124 125 126 127 128 129 130 131 133 134 135 136 137 138 139 140 141 142\n",
      " 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160\n",
      " 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178\n",
      " 179]\n"
     ]
    }
   ],
   "source": [
    "all_nodes = np.union1d(df['FROM_NODE'].unique(),df['TO_NODE'].unique())\n",
    "print(all_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the cyclic paths in the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe to make the traversal easier/faster\n",
    "df2 = df.sort_values(['FROM_NODE','TO_NODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to represent the graph.\n",
    "# Keys are the from_nodes and the value is a list of destination nodes\n",
    "Graph = {}\n",
    "for index, row in df2.iterrows():\n",
    "    from_n = df.loc[index,'FROM_NODE'].astype(int)\n",
    "    to_n = df.loc[index,'TO_NODE'].astype(int)\n",
    "    \n",
    "    if from_n in Graph.keys():\n",
    "        Graph[from_n].append(to_n)\n",
    "        \n",
    "    else:\n",
    "        Graph[from_n] = [to_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cycles(graph, start_node, end_node):\n",
    "    # Initialize a cycle with the initial node and an empty array representing an unknown route\n",
    "    cycle = [(start_node, [])]\n",
    "    \n",
    "    while cycle:\n",
    "        current, route = cycle.pop()\n",
    "        # If a route exists and the last node in the route is same as the first, pass back the route\n",
    "        if route and current == end_node:\n",
    "            yield route\n",
    "            continue\n",
    "        try:\n",
    "            for next_node in graph[current]:\n",
    "                if next_node in route:\n",
    "                    continue\n",
    "                cycle.append((next_node, route+[next_node]))\n",
    "        except:\n",
    "            # If the node does not exist in the source node of the graph, it will cause an exception in the above code\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the cycles in the graph\n",
    "\n",
    "\"\"\"To find the cycles in the graph, we do not need to iterate over ALL the source nodes. Based on the set above, \n",
    "nodes_to_search, only these nodes have sink nodes that can create a cycle.\n",
    "\n",
    "Therefore, in the list comprehension below, we limit the search to start only from these nodes. For large graphs, \n",
    "this may help reduce the iterations needed. \n",
    "\"\"\"\n",
    "\n",
    "cycles = [[node]+path  for node in nodes_to_search for path in find_cycles(Graph, node, node)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cycles found: 44\n",
      "First few cycles:\n",
      "[[10, 90, 100, 76, 10], [10, 90, 76, 10], [10, 90, 62, 10], [10, 76, 90, 62, 10], [10, 76, 10]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of cycles found: {len(cycles)}\")\n",
    "print(\"First few cycles:\")      \n",
    "print(cycles[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Value = 14,857,612,120.26\n",
      "Maximum Value = 743,000,235.0 at Cycle = [10, 70, 171, 178, 90, 100, 76, 10]\n"
     ]
    }
   ],
   "source": [
    "# We get the values from the original dataframe.\n",
    "total_values = 0\n",
    "max_value = 0\n",
    "max_cycle = None\n",
    "for cycle in cycles:\n",
    "    values = []\n",
    "    for idx in range(0,len(cycle)-1):\n",
    "        from_node = cycle[idx]\n",
    "        to_node = cycle[idx+1]\n",
    "        \n",
    "        values.append( df2.loc[(df2['FROM_NODE']==from_node) & (df2['TO_NODE']==to_node),'VALUE'].sum())\n",
    "        \n",
    "    # Total value in this cycle\n",
    "    value_sum = np.sum(values)\n",
    "    \n",
    "    total_values += value_sum\n",
    "    if value_sum > max_value:\n",
    "        max_value=value_sum\n",
    "        max_cycle=cycle\n",
    "\n",
    "print(f\"Total Value = {total_values:,.2f}\") # Round to 2 dec places\n",
    "print(f\"Maximum Value = {max_value:,} at Cycle = {max_cycle}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
